{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8c55ab3e"
   },
   "source": [
    "# Check version and cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4581,
     "status": "ok",
     "timestamp": 1691770393932,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "a4a02b4d",
    "outputId": "dd704b28-22a9-478a-d132-b65df414a044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu118\n",
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"cuda: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60d445ae"
   },
   "source": [
    "# About parameters\n",
    "1. batch size\n",
    "2. device\n",
    "3. path of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1691770396920,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "3c0a6bb8"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "batch_size = 2\n",
    "training_pth = \"/content/drive/MyDrive/Colab Notebooks/UNet/fundus/training\"\n",
    "testing_pth = \"/content/drive/MyDrive/Colab Notebooks/UNet/fundus/testing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af0b06d4"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dca7a65"
   },
   "source": [
    "## data augmentation\n",
    "1. randomly augmentation\n",
    "2. 0:vertical flip, 1: horizontal flip, 2, horizontal and vertical flip, 3: nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1326,
     "status": "ok",
     "timestamp": 1691770404383,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "40c91eb9"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = {\n",
    "    0:transforms.Compose([transforms.Grayscale(),\n",
    "                          transforms.RandomVerticalFlip(p=1.0),\n",
    "                          transforms.ToTensor()]),\n",
    "    1:transforms.Compose([transforms.Grayscale(),\n",
    "                          transforms.RandomHorizontalFlip(p=1.0),\n",
    "                          transforms.ToTensor()]),\n",
    "    2:transforms.Compose([transforms.Grayscale(),\n",
    "                          transforms.RandomHorizontalFlip(p=1.0),\n",
    "                          transforms.RandomVerticalFlip(p=1.0),\n",
    "                          transforms.ToTensor()]),\n",
    "    3:transforms.Compose([transforms.Grayscale(),\n",
    "                          transforms.ToTensor()])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ff9815c"
   },
   "source": [
    "## customized dataset and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1691770408588,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "dbc6101e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomizedDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        img_root = os.path.join(root, \"images\") # image path\n",
    "        lbl_root = os.path.join(root, \"label\")  # label path\n",
    "\n",
    "        img_length = len(os.listdir(img_root))   # length of image\n",
    "        lel_length = len(os.listdir(lbl_root))   # length of label\n",
    "\n",
    "        self.img = [f\"{img_root}/{i}.png\" for i in range(img_length)] # correct road and filename in sequentially\n",
    "        self.lbl = [f\"{lbl_root}/{i}.png\" for i in range(lel_length)] # correct road and filename in sequentially\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_pth = self.img[index]\n",
    "        label_pth = self.lbl[index]\n",
    "\n",
    "        image = Image.open(image_pth)\n",
    "        label = Image.open(label_pth)\n",
    "\n",
    "        # augmentation\n",
    "        flip_code = random.choice([0, 1, 2, 3])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform[flip_code](image)\n",
    "            lbl = self.transform[flip_code](label)\n",
    "\n",
    "        # convert pixel of label into 0 and 1\n",
    "        # because out task is segmentation, it actually is a binary classification work\n",
    "        # set pixel to 0 or 1 to help us classify forward and backward\n",
    "        # but ToTensor() has alread included this step\n",
    "#        if lbl.max() > 1:\n",
    "#            lbl = lbl / 255\n",
    "\n",
    "        return img, lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25177,
     "status": "ok",
     "timestamp": 1691770438375,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "70eae0e0",
    "outputId": "05dc976b-9956-405b-af13-eec67e354297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset: 20\n",
      "\n",
      "batch: 1\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 2\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 3\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 4\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 5\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 6\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 7\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 8\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 9\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n",
      "batch: 10\n",
      "---------------\n",
      "image size = torch.Size([2, 1, 512, 512])\n",
      "label size = torch.Size([2, 1, 512, 512])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "train_ds = CustomizedDataset(training_pth, transform)\n",
    "print(f\"length of dataset: {len(train_ds)}\\n\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "i = 0\n",
    "for image, label in train_dl:\n",
    "    i += 1\n",
    "    print(f\"batch: {i}\\n\" + f\"-\"*15)\n",
    "    print(f\"image size = {image.size()}\\nlabel size = {label.size()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7f1a22e",
    "tags": []
   },
   "source": [
    "# U-Net architecture\n",
    "![U-Net architecture][https://reurl.cc/p6eW7d]\n",
    "1. According to original U-Net architecture, the output size of image will smaller than input\n",
    "2. so we have to modify slightly its atchitecture making the output size equal input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f1883d5"
   },
   "source": [
    "## down sampling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1691770478019,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "f7b2d3d9"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "########## double convolution ##########\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.double_conv(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "########## down sampling ##########\n",
    "class DownSampling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.down_sampling = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.down_sampling(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef496054"
   },
   "source": [
    "## up sampling module\n",
    "(1) In up sampling stage, it include two step\n",
    "\n",
    "1. first, use transpose convolution (or bilinear) to enlarge each feather map\n",
    "2. second, padding the feature map from up sampling then concact another feature map from down sampling\n",
    "\n",
    "(2) reference: https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad (F.pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1691770482846,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "68b2f3d2"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=False):\n",
    "        super().__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Unsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        parameters\n",
    "        -----\n",
    "        x1: features after upsample, size = [batch, C, H, W]\n",
    "        x2: features in skip architecture, size = [batch, C, H, W]\n",
    "        \"\"\"\n",
    "\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diff_h = torch.tensor(x2.size()[2] - x1.size()[2]) # difference of hight\n",
    "        diff_w = torch.tensor(x2.size()[3] - x1.size()[3]) # difference of width\n",
    "\n",
    "        # padding\n",
    "        ######################################################\n",
    "        # padding參數如果設為[diff_w//2, diff_w//2, diff_h//2, diff_h//2], 則只能針對邊長差為偶數的使用\n",
    "        # ex:  (H, W)=(3, 3) -> (H, W)=(7, 7) 或 (H, W)=(2, 2) -> (H, W)=(8, 8)\n",
    "        # 若是邊長差為奇數, 則會有少padding的情況發生\n",
    "        # ex: (H, W)=(3, 3) -> (H, W)=(10, 10)\n",
    "        # 因此應該寫成[diff_w//2, diff_w - diff_w//2, diff_h//2, diff_h - diff_h//2]\n",
    "        ######################################################\n",
    "        x1 = F.pad(x1, [diff_w//2, diff_w - diff_w//2, diff_h//2, diff_h - diff_h//2])\n",
    "\n",
    "        # concat and convolution\n",
    "        x = torch.cat([x2, x1], dim=1) # concat along channel dimension\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec3d34c1-b9f9-4c10-9668-cfd0b774d71c"
   },
   "source": [
    "## output convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1691770489806,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "734bc324-d11e-479f-bc57-7e49a92e6034"
   },
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "377c198a-5324-4449-92a7-7eb3f0e8901b"
   },
   "source": [
    "# Completed U-Net model\n",
    "for instance, **input size (C, H, W)=(1, 512, 512)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 945,
     "status": "ok",
     "timestamp": 1691770497544,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "c0bdd933-3084-4c56-b4b3-4555679b2dee"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "        ----------\n",
    "        n_channels: intput channel\n",
    "        n_classes: number of class\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # down sampling\n",
    "        self.in_channels = DoubleConv(n_channels, 64) # [1, 512, 512]   -> [64, 512, 512]  -> [64, 512, 512]\n",
    "        self.down_1 = DownSampling(64, 128)           # [64, 512, 512]  -> [64, 256, 256]  -> [128, 256, 256] -> [128, 256, 256]\n",
    "        self.down_2 = DownSampling(128, 256)          # [128, 256, 256] -> [128, 128, 128] -> [256, 128, 128] -> [256, 128, 128]\n",
    "        self.down_3 = DownSampling(256, 512)          # [256, 128, 128] -> [256, 64, 64]   -> [512, 64, 64]   -> [512, 64, 64]\n",
    "        self.down_4 = DownSampling(512, 1024)         # [512, 64, 64]   -> [512, 32, 32]   -> [1024, 32, 32]  -> [1024, 32, 32]\n",
    "\n",
    "        # up sampling\n",
    "        self.up_1 = Up(1024, 512, bilinear) # [1024, 32, 32]  -> [1024, 64, 64]  -> [512, 64, 64]   -> [512, 64, 64]\n",
    "        self.up_2 = Up(512, 256, bilinear)  # [512, 64, 64]   -> [512, 128, 128] -> [256, 128, 128] -> [256, 128, 128]\n",
    "        self.up_3 = Up(256, 128, bilinear)  # [256, 128, 128] -> [256, 256, 256] -> [128, 256, 256] -> [128, 256, 256]\n",
    "        self.up_4 = Up(128, 64, bilinear)   # [128, 256, 256] -> [128, 512, 512] -> [64, 512, 512]  -> [64, 512, 512]\n",
    "\n",
    "        # output\n",
    "        self.out_channels = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # down sampling\n",
    "        x1 = self.in_channels(x)\n",
    "        x2 = self.down_1(x1)\n",
    "        x3 = self.down_2(x2)\n",
    "        x4 = self.down_3(x3)\n",
    "        x5 = self.down_4(x4)\n",
    "\n",
    "        # up sampling\n",
    "        x = self.up_1(x5, x4)\n",
    "        x = self.up_2(x, x3)\n",
    "        x = self.up_3(x, x2)\n",
    "        x = self.up_4(x, x1)\n",
    "        x = self.out_channels(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1691770503117,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "0bc36789-1647-4c91-9910-f21e7dc23e23",
    "outputId": "3091ff68-f4c8-45c9-fbd6-ddc563d44bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels\n",
      "DoubleConv(\n",
      "  (double_conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "down_1\n",
      "DownSampling(\n",
      "  (down_sampling): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "down_2\n",
      "DownSampling(\n",
      "  (down_sampling): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "down_3\n",
      "DownSampling(\n",
      "  (down_sampling): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "down_4\n",
      "DownSampling(\n",
      "  (down_sampling): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "up_1\n",
      "Up(\n",
      "  (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "up_2\n",
      "Up(\n",
      "  (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "up_3\n",
      "Up(\n",
      "  (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "up_4\n",
      "Up(\n",
      "  (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (conv): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "out_channels\n",
      "OutConv(\n",
      "  (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# observe model architecture\n",
    "model = UNet(n_channels=1, n_classes=1)\n",
    "for name, layer in model.named_children():\n",
    "    print(name)\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9575ba1-aaf9-40b3-bab6-efcd44434caf",
    "outputId": "491f7cdd-7162-4678-ad83-5db9f5fa2bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 512, 512]             640\n",
      "       BatchNorm2d-2         [-1, 64, 512, 512]             128\n",
      "              ReLU-3         [-1, 64, 512, 512]               0\n",
      "            Conv2d-4         [-1, 64, 512, 512]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 512, 512]             128\n",
      "              ReLU-6         [-1, 64, 512, 512]               0\n",
      "        DoubleConv-7         [-1, 64, 512, 512]               0\n",
      "         MaxPool2d-8         [-1, 64, 256, 256]               0\n",
      "            Conv2d-9        [-1, 128, 256, 256]          73,856\n",
      "      BatchNorm2d-10        [-1, 128, 256, 256]             256\n",
      "             ReLU-11        [-1, 128, 256, 256]               0\n",
      "           Conv2d-12        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-13        [-1, 128, 256, 256]             256\n",
      "             ReLU-14        [-1, 128, 256, 256]               0\n",
      "       DoubleConv-15        [-1, 128, 256, 256]               0\n",
      "     DownSampling-16        [-1, 128, 256, 256]               0\n",
      "        MaxPool2d-17        [-1, 128, 128, 128]               0\n",
      "           Conv2d-18        [-1, 256, 128, 128]         295,168\n",
      "      BatchNorm2d-19        [-1, 256, 128, 128]             512\n",
      "             ReLU-20        [-1, 256, 128, 128]               0\n",
      "           Conv2d-21        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-22        [-1, 256, 128, 128]             512\n",
      "             ReLU-23        [-1, 256, 128, 128]               0\n",
      "       DoubleConv-24        [-1, 256, 128, 128]               0\n",
      "     DownSampling-25        [-1, 256, 128, 128]               0\n",
      "        MaxPool2d-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27          [-1, 512, 64, 64]       1,180,160\n",
      "      BatchNorm2d-28          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-29          [-1, 512, 64, 64]               0\n",
      "           Conv2d-30          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-31          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-32          [-1, 512, 64, 64]               0\n",
      "       DoubleConv-33          [-1, 512, 64, 64]               0\n",
      "     DownSampling-34          [-1, 512, 64, 64]               0\n",
      "        MaxPool2d-35          [-1, 512, 32, 32]               0\n",
      "           Conv2d-36         [-1, 1024, 32, 32]       4,719,616\n",
      "      BatchNorm2d-37         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-38         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-39         [-1, 1024, 32, 32]       9,438,208\n",
      "      BatchNorm2d-40         [-1, 1024, 32, 32]           2,048\n",
      "             ReLU-41         [-1, 1024, 32, 32]               0\n",
      "       DoubleConv-42         [-1, 1024, 32, 32]               0\n",
      "     DownSampling-43         [-1, 1024, 32, 32]               0\n",
      "  ConvTranspose2d-44          [-1, 512, 64, 64]       2,097,664\n",
      "           Conv2d-45          [-1, 512, 64, 64]       4,719,104\n",
      "      BatchNorm2d-46          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-47          [-1, 512, 64, 64]               0\n",
      "           Conv2d-48          [-1, 512, 64, 64]       2,359,808\n",
      "      BatchNorm2d-49          [-1, 512, 64, 64]           1,024\n",
      "             ReLU-50          [-1, 512, 64, 64]               0\n",
      "       DoubleConv-51          [-1, 512, 64, 64]               0\n",
      "               Up-52          [-1, 512, 64, 64]               0\n",
      "  ConvTranspose2d-53        [-1, 256, 128, 128]         524,544\n",
      "           Conv2d-54        [-1, 256, 128, 128]       1,179,904\n",
      "      BatchNorm2d-55        [-1, 256, 128, 128]             512\n",
      "             ReLU-56        [-1, 256, 128, 128]               0\n",
      "           Conv2d-57        [-1, 256, 128, 128]         590,080\n",
      "      BatchNorm2d-58        [-1, 256, 128, 128]             512\n",
      "             ReLU-59        [-1, 256, 128, 128]               0\n",
      "       DoubleConv-60        [-1, 256, 128, 128]               0\n",
      "               Up-61        [-1, 256, 128, 128]               0\n",
      "  ConvTranspose2d-62        [-1, 128, 256, 256]         131,200\n",
      "           Conv2d-63        [-1, 128, 256, 256]         295,040\n",
      "      BatchNorm2d-64        [-1, 128, 256, 256]             256\n",
      "             ReLU-65        [-1, 128, 256, 256]               0\n",
      "           Conv2d-66        [-1, 128, 256, 256]         147,584\n",
      "      BatchNorm2d-67        [-1, 128, 256, 256]             256\n",
      "             ReLU-68        [-1, 128, 256, 256]               0\n",
      "       DoubleConv-69        [-1, 128, 256, 256]               0\n",
      "               Up-70        [-1, 128, 256, 256]               0\n",
      "  ConvTranspose2d-71         [-1, 64, 512, 512]          32,832\n",
      "           Conv2d-72         [-1, 64, 512, 512]          73,792\n",
      "      BatchNorm2d-73         [-1, 64, 512, 512]             128\n",
      "             ReLU-74         [-1, 64, 512, 512]               0\n",
      "           Conv2d-75         [-1, 64, 512, 512]          36,928\n",
      "      BatchNorm2d-76         [-1, 64, 512, 512]             128\n",
      "             ReLU-77         [-1, 64, 512, 512]               0\n",
      "       DoubleConv-78         [-1, 64, 512, 512]               0\n",
      "               Up-79         [-1, 64, 512, 512]               0\n",
      "           Conv2d-80          [-1, 2, 512, 512]             130\n",
      "          OutConv-81          [-1, 2, 512, 512]               0\n",
      "================================================================\n",
      "Total params: 31,042,434\n",
      "Trainable params: 31,042,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.00\n",
      "Forward/backward pass size (MB): 4084.00\n",
      "Params size (MB): 118.42\n",
      "Estimated Total Size (MB): 4203.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (1, 512, 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbd9a762-9ca0-4c08-8ce1-a8902c2d3781",
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "678edf0b-f0c4-4a40-b7bb-e43de0c16772"
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1691770530315,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "53ef2ea0-d7fd-4cb0-bb33-7828e2cc70e6"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = CustomizedDataset(training_pth, transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08ecb24e-73fd-423f-a1a1-54529af11470"
   },
   "source": [
    "## model, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5456,
     "status": "ok",
     "timestamp": 1691770542810,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "157871c0-98f5-4acc-9130-5c1e05d92d4d"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# model setting\n",
    "n_channels = 1\n",
    "n_classes = 1\n",
    "model = UNet(n_channels, n_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss and optimizer\n",
    "lr = 0.00001\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.00001, weight_decay=1e-8, momentum=0.9)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12a3a29d-4923-4aef-8fdb-4db1ff4e97b3"
   },
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 264276,
     "status": "ok",
     "timestamp": 1691770820417,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "d315815c-8ca9-41cf-8123-f5fdb21f70be",
    "outputId": "d356c176-cbba-40c8-c5fc-62f52efccf46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50\n",
      "---------------\n",
      "loss: 0.700443\n",
      "\n",
      "Epoch: 2/50\n",
      "---------------\n",
      "loss: 0.583812\n",
      "\n",
      "Epoch: 3/50\n",
      "---------------\n",
      "loss: 0.520095\n",
      "\n",
      "Epoch: 4/50\n",
      "---------------\n",
      "loss: 0.472994\n",
      "\n",
      "Epoch: 5/50\n",
      "---------------\n",
      "loss: 0.440371\n",
      "\n",
      "Epoch: 6/50\n",
      "---------------\n",
      "loss: 0.420152\n",
      "\n",
      "Epoch: 7/50\n",
      "---------------\n",
      "loss: 0.407083\n",
      "\n",
      "Epoch: 8/50\n",
      "---------------\n",
      "loss: 0.394899\n",
      "\n",
      "Epoch: 9/50\n",
      "---------------\n",
      "loss: 0.385398\n",
      "\n",
      "Epoch: 10/50\n",
      "---------------\n",
      "loss: 0.374362\n",
      "\n",
      "Epoch: 11/50\n",
      "---------------\n",
      "loss: 0.367852\n",
      "\n",
      "Epoch: 12/50\n",
      "---------------\n",
      "loss: 0.368639\n",
      "\n",
      "Epoch: 13/50\n",
      "---------------\n",
      "loss: 0.364101\n",
      "\n",
      "Epoch: 14/50\n",
      "---------------\n",
      "loss: 0.356684\n",
      "\n",
      "Epoch: 15/50\n",
      "---------------\n",
      "loss: 0.352007\n",
      "\n",
      "Epoch: 16/50\n",
      "---------------\n",
      "loss: 0.347091\n",
      "\n",
      "Epoch: 17/50\n",
      "---------------\n",
      "loss: 0.343455\n",
      "\n",
      "Epoch: 18/50\n",
      "---------------\n",
      "loss: 0.339819\n",
      "\n",
      "Epoch: 19/50\n",
      "---------------\n",
      "loss: 0.335475\n",
      "\n",
      "Epoch: 20/50\n",
      "---------------\n",
      "loss: 0.332111\n",
      "\n",
      "Epoch: 21/50\n",
      "---------------\n",
      "loss: 0.328691\n",
      "\n",
      "Epoch: 22/50\n",
      "---------------\n",
      "loss: 0.326467\n",
      "\n",
      "Epoch: 23/50\n",
      "---------------\n",
      "loss: 0.323762\n",
      "\n",
      "Epoch: 24/50\n",
      "---------------\n",
      "loss: 0.322869\n",
      "\n",
      "Epoch: 25/50\n",
      "---------------\n",
      "loss: 0.319623\n",
      "\n",
      "Epoch: 26/50\n",
      "---------------\n",
      "loss: 0.315901\n",
      "\n",
      "Epoch: 27/50\n",
      "---------------\n",
      "loss: 0.313313\n",
      "\n",
      "Epoch: 28/50\n",
      "---------------\n",
      "loss: 0.310905\n",
      "\n",
      "Epoch: 29/50\n",
      "---------------\n",
      "loss: 0.309252\n",
      "\n",
      "Epoch: 30/50\n",
      "---------------\n",
      "loss: 0.306509\n",
      "\n",
      "Epoch: 31/50\n",
      "---------------\n",
      "loss: 0.305424\n",
      "\n",
      "Epoch: 32/50\n",
      "---------------\n",
      "loss: 0.302471\n",
      "\n",
      "Epoch: 33/50\n",
      "---------------\n",
      "loss: 0.300460\n",
      "\n",
      "Epoch: 34/50\n",
      "---------------\n",
      "loss: 0.297736\n",
      "\n",
      "Epoch: 35/50\n",
      "---------------\n",
      "loss: 0.295006\n",
      "\n",
      "Epoch: 36/50\n",
      "---------------\n",
      "loss: 0.293789\n",
      "\n",
      "Epoch: 37/50\n",
      "---------------\n",
      "loss: 0.291970\n",
      "\n",
      "Epoch: 38/50\n",
      "---------------\n",
      "loss: 0.290323\n",
      "\n",
      "Epoch: 39/50\n",
      "---------------\n",
      "loss: 0.287338\n",
      "\n",
      "Epoch: 40/50\n",
      "---------------\n",
      "loss: 0.285404\n",
      "\n",
      "Epoch: 41/50\n",
      "---------------\n",
      "loss: 0.284361\n",
      "\n",
      "Epoch: 42/50\n",
      "---------------\n",
      "loss: 0.282044\n",
      "\n",
      "Epoch: 43/50\n",
      "---------------\n",
      "loss: 0.279892\n",
      "\n",
      "Epoch: 44/50\n",
      "---------------\n",
      "loss: 0.278173\n",
      "\n",
      "Epoch: 45/50\n",
      "---------------\n",
      "loss: 0.276195\n",
      "\n",
      "Epoch: 46/50\n",
      "---------------\n",
      "loss: 0.274628\n",
      "\n",
      "Epoch: 47/50\n",
      "---------------\n",
      "loss: 0.272563\n",
      "\n",
      "Epoch: 48/50\n",
      "---------------\n",
      "loss: 0.270903\n",
      "\n",
      "Epoch: 49/50\n",
      "---------------\n",
      "loss: 0.268952\n",
      "\n",
      "Epoch: 50/50\n",
      "---------------\n",
      "loss: 0.267062\n",
      "\n",
      "training time: 0.0 hr 4.0 min 24.01947522163391 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.train()\n",
    "best_loss = float(\"inf\")\n",
    "loss_list = []\n",
    "\n",
    "since = time.time()\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(f\"Epoch: {epoch}/{epochs}\")\n",
    "    print('-' * 15)\n",
    "\n",
    "    batch_loss = 0\n",
    "\n",
    "    for data, label in train_dl:\n",
    "        data, label = data.to(device, dtype=torch.float32), label.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_loss += loss.item() * data.size(0)\n",
    "\n",
    "    epoch_loss = batch_loss / len(train_ds)\n",
    "    loss_list.append(epoch_loss)\n",
    "    print(f\"loss: {epoch_loss:.6f}\\n\")\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_model_weight = model.state_dict()\n",
    "\n",
    "times = time.time() - since\n",
    "print(f\"training time: {times//3600} hr {(times//60)%60} min {times%60} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19b84e72-34ed-4ad2-bddd-69063e825f6c"
   },
   "source": [
    "## visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1691770840385,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "e5b64f49-d264-434c-b8bd-ff70388ed7bc",
    "outputId": "68ab77b0-b927-4d1a-ab5c-c35476aab314"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, epochs+1), loss_list)\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80fd4476-edfc-4b72-a5c3-8867a3d56c65"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18964,
     "status": "ok",
     "timestamp": 1691771052768,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "8a9c28f0-842e-4fb9-a5c9-25e16aa0f440",
    "outputId": "e47d63d9-44b9-46f8-a78b-25a7eafd803e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 2\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 3\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 4\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 5\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 6\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 7\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 8\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 9\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 10\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 11\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 12\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 13\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 14\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 15\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 16\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 17\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 18\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n",
      "time: 19\n",
      "---------------\n",
      "image size: torch.Size([1, 1, 512, 512])\n",
      "label size: torch.Size([1, 1, 512, 512])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## transform ##########\n",
    "transform_test = transforms.Compose([transforms.Grayscale(),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "########## dataset and dataloader ##########\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        img_path = os.path.join(root, \"images\") # image path\n",
    "        lbl_path = os.path.join(root, \"label\")  # label path\n",
    "\n",
    "        img_length = len(os.listdir(img_path))  # image length\n",
    "        lbl_length = len(os.listdir(img_path))    # label length\n",
    "\n",
    "        self.img = [f\"{img_path}/{i}.png\" for i in range(1, img_length+1)]\n",
    "        self.lbl = [f\"{lbl_path}/{i}.png\" for i in range(1, lbl_length+1)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.img[index]\n",
    "        label_path = self.lbl[index]\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        lbl = Image.open(label_path)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            lbl = self.transform(lbl)\n",
    "\n",
    "        return img, lbl\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "\n",
    "########## check dataset and dataloader ##########\n",
    "batch_size = 1\n",
    "test_ds = TestDataset(testing_pth, transform=transform_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "i = 0\n",
    "for img, lbl in test_dl:\n",
    "    i += 1\n",
    "    print(f\"time: {i}\")\n",
    "    print('-' * 15)\n",
    "    print(f\"image size: {img.size()}\\nlabel size: {lbl.size()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7746,
     "status": "ok",
     "timestamp": 1691771319424,
     "user": {
      "displayName": "陳劭驊",
      "userId": "04838775255713790535"
     },
     "user_tz": -480
    },
    "id": "11155108-7500-48a3-a5b4-ea7ecb2201ac",
    "outputId": "bc6573ef-7119-4d84-ef63-18ff4ce66055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 2\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 3\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 4\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 5\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 6\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 7\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 8\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 9\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 10\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 11\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 12\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 13\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 14\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 15\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 16\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 17\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 18\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "batch: 19\n",
      "---------------\n",
      "save image: complete !\n",
      "compute iou: complete !\n",
      "mean IOU score: 0.589193832342216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "########## compute iou score ##########\n",
    "def IOU(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    iou = tp / (fp + fn + tp)\n",
    "\n",
    "    return iou\n",
    "\n",
    "########## testing ##########\n",
    "save_path = \"/content/drive/MyDrive/Colab Notebooks/UNet/fundus/testing/label\"\n",
    "\n",
    "model.load_state_dict(best_model_weight)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "iou_list = []\n",
    "with torch.no_grad():\n",
    "    for i, (data, label) in enumerate(test_dl):\n",
    "        print(f\"batch: {i+1}\")\n",
    "        print('-' * 15)\n",
    "        data, label = data.to(device, dtype=torch.float32), label.to(device, dtype=torch.float32)\n",
    "\n",
    "        output = model(data) # output size: [b, C, H, W]=[1, 1, 512, 512]\n",
    "\n",
    "        ############### save predicted image ###############\n",
    "        pred = torch.squeeze(output, dim=1)      # pred_img size = [1, 512, 512]\n",
    "        pred[pred >= 0.5] = 1\n",
    "        pred[pred < 0.5] = 0\n",
    "        pred_img = transforms.ToPILImage()(pred) # convert into PIL format\n",
    "        pred_img.save(f\"{save_path}/{i+1}_pred.png\")\n",
    "\n",
    "        print(\"save image: complete !\")\n",
    "        ####################################################\n",
    "\n",
    "        ############## compute mean iou score ##############\n",
    "        y_true = torch.flatten(label)\n",
    "        y_true[y_true >= 0.5] = 1\n",
    "        y_true[y_true < 0.5] = 0\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "\n",
    "        y_pred = torch.flatten(pred)\n",
    "        y_pred = y_pred.detach().cpu().numpy()\n",
    "\n",
    "        iou = IOU(y_true, y_pred)\n",
    "        iou_list.append(iou)\n",
    "\n",
    "        print(\"compute iou: complete !\")\n",
    "        ####################################################\n",
    "\n",
    "print(f\"mean IOU score: {sum(iou_list)/len(iou_list)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fMw1bzeb2L8"
   },
   "source": [
    "# Conclusion\n",
    "一些血管中**更細微的末梢血管**不能很好的分割"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
